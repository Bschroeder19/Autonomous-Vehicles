{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fec93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the camera video data recorded in this lab, work with your team to create a\n",
    "# shared Python code on GitHub that successfully identifies the following objects:\n",
    "### At least one pedestrian\n",
    "### At least one stop sign\n",
    "### At least one vehicle\n",
    "### Any other object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816bf591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "537c83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the COCO class labels:\n",
    "class_names = open(\"coco.names\").read().strip().split(\"\\n\")\n",
    "\n",
    "# Load the serialized caffe model from disk:\n",
    "net = cv2.dnn.readNetFromDarknet(\"yolov3.cfg\", \"yolov3.weights\")\n",
    "\n",
    "def process(image):\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # Get the output layer names:\n",
    "    layer_names = net.getLayerNames()\n",
    "    layer_names = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # Create the blob with a size of (416, 416), swap red and blue channels\n",
    "    # and also a scale factor of 1/255 = 0,003921568627451:\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    print(blob.shape)\n",
    "\n",
    "    # Feed the input blob to the network, perform inference and get the output:\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(layer_names)\n",
    "\n",
    "    # Get inference time:\n",
    "    t, _ = net.getPerfProfile()\n",
    "    print('Inference time: %.2f ms' % (t * 1000.0 / cv2.getTickFrequency()))\n",
    "\n",
    "    # Initialization:\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # Get class ID and confidence of the current detection:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Filter out weak predictions:\n",
    "            if confidence > 0.25:\n",
    "                # Scale the bounding box coordinates (center, width, height) using the dimensions of the original image:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # Calculate the top-left corner of the bounding box:\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # Update the information we have for each detection:\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # We can apply non-maxima suppression (eliminate weak and overlapping bounding boxes):\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "\n",
    "    # Show the results (if any object is detected after non-maxima suppression):\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            # Extract the (previously recalculated) bounding box coordinates:\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            # Draw label and confidence:\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            label = \"{}: {:.4f}\".format(class_names[class_ids[i]], confidences[i])\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "            y = max(y, labelSize[1])\n",
    "            cv2.rectangle(image, (x, y - labelSize[1]), (x + labelSize[0], y + 0), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(image, label, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d01abe4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"Lab3Video1_Trim.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"Lab3Video1_Trim.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "821f87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Lab3Video1_Trim.mp4')\n",
    "\n",
    "writer = cv2.VideoWriter('StopSign.avi', cv2.VideoWriter_fourcc(*'MJPG'), 20, (int(width/2),height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c53038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 416, 416)\n",
      "Inference time: 1745.08 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 1033.30 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 1089.16 ms\n"
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    frame = process(frame)\n",
    "    \n",
    "    writer.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c502aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"Lab3Video2_Trim.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('Lab3Video2_Trim.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5908163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = cv2.VideoCapture('Lab3Video2_Trim.mp4')\n",
    "\n",
    "writer = cv2.VideoWriter('BillyWalking.avi', cv2.VideoWriter_fourcc(*'MJPG'), 20, (int(width/2),height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "806b4aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 416, 416)\n",
      "Inference time: 1852.94 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 850.99 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 777.11 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 811.80 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 784.52 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 788.59 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 788.93 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 805.10 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 781.24 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 965.90 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 912.65 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 806.70 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 777.51 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 773.47 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 790.47 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 783.93 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 784.44 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 829.46 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 797.84 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 838.46 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 816.78 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 825.75 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 777.20 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 941.93 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 932.84 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 1082.89 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 1147.20 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 1149.21 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 1036.20 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 1055.74 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 918.65 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 872.89 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 867.42 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 928.48 ms\n"
     ]
    }
   ],
   "source": [
    "while(caps.isOpened()):\n",
    "    ret, frame = caps.read()\n",
    "    frame = process(frame)\n",
    "    \n",
    "    writer.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05946340",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"Lab3Video3_Trim.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('Lab3Video3_Trim.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff501884",
   "metadata": {},
   "outputs": [],
   "source": [
    "capz = cv2.VideoCapture('Lab3Video3_Trim.mp4')\n",
    "\n",
    "writer = cv2.VideoWriter('Cars_and_Parking_Garage.avi', cv2.VideoWriter_fourcc(*'MJPG'), 20, (int(width/2),height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "565e8d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 416, 416)\n",
      "Inference time: 2147.77 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 903.80 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 791.51 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 782.96 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 866.72 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 971.57 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 848.05 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 823.53 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 778.49 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 776.68 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 799.49 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 769.69 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 787.88 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 820.05 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 871.36 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 813.84 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 794.36 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 776.82 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 801.97 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 792.61 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 788.39 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 793.30 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 987.73 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 904.73 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 804.08 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 793.89 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 778.92 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 775.33 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 818.12 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 796.21 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 775.68 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 792.10 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 789.93 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 785.81 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 780.48 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 783.45 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 782.07 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 792.77 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 776.27 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 895.90 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 1086.72 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 977.71 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 805.70 ms\n"
     ]
    }
   ],
   "source": [
    "while(capz.isOpened()):\n",
    "    ret, frame = capz.read()\n",
    "    frame = process(frame)\n",
    "    \n",
    "    writer.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ba5a878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"Lab3Video4_Trim.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('Lab3Video4_Trim.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dea88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "capx = cv2.VideoCapture('Lab3Video4_Trim.mp4')\n",
    "\n",
    "writer = cv2.VideoWriter('Top_Of_Ramp.avi', cv2.VideoWriter_fourcc(*'MJPG'), 20, (int(width/2),height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c406067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 416, 416)\n",
      "Inference time: 1824.06 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 987.77 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 804.43 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 796.33 ms\n",
      "(1, 3, 416, 416)\n",
      "Inference time: 782.91 ms\n"
     ]
    }
   ],
   "source": [
    "while(capx.isOpened()):\n",
    "    ret, frame = capx.read()\n",
    "    frame = process(frame)\n",
    "    \n",
    "    writer.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
